"""
å®Œæ•´ç³»ç»Ÿè¿è¡Œè„šæœ¬ - ä½¿ç”¨çœŸå®LSTMæ¨¡å‹æ•°æ®
"""

import json
import subprocess
import pandas as pd
from pathlib import Path
import os

def create_config():
    """åˆ›å»ºé…ç½®æ–‡ä»¶"""
    config = {
        "project": {
            "name": "æ™ºé“¾æ–°çºª-äº¬ä¸œè¯„è®ºæƒ…æ„Ÿåˆ†æ",
            "description": "åŸºäºçœŸå®LSTMæ¨¡å‹æ•°æ®çš„å¯¹æ¯”åˆ†æç³»ç»Ÿ"
        },
        "data": {
            "text_column": "sentence",
            "label_column": "label",
            "dataset_column": "dataset",
            "use_original_split": True,
            "max_length": 200,
            "balance_data": True,
            "sample_size": 5000
        },
        "models": {
            "NaiveBayes": {
                "use": True,
                "alpha": 1.0
            },
            "SVM": {
                "use": True,
                "C": 1.0,
                "kernel": "linear",
                "probability": True
            },
            "LSTM": {
                "use": True,
                "embedding_dim": 128,
                "hidden_dim": 256,
                "num_layers": 2,
                "dropout": 0.5,
                "bidirectional": True,
                "use_attention": True,
                "attention_type": "self"
            },
            "BERT": {
                "use": True,
                "model_name": "bert-base-chinese",
                "max_length": 64,
                "batch_size": 8,
                "num_labels": 2
            }
        },
        "training": {
            "epochs": 15,
            "batch_size": 32,
            "learning_rate": 0.001,
            "bert_learning_rate": 2e-5,
            "optimizer": "adam",
            "early_stopping_patience": 5,
            "save_best": True,
            "log_interval": 50
        },
        "evaluation": {
            "metrics": ["accuracy", "precision", "recall", "f1"],
            "generate_report": True,
            "plot_results": True,
            "save_predictions": True
        },
        "paths": {
            "data_dir": "data",
            "models_dir": "models",
            "results_dir": "results",
            "plots_dir": "results/performance_plots",
            "logs_dir": "logs"
        }
    }

    with open('config_complete_updated.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)

    print("âœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º: config_complete_updated.json")
    return 'config_complete_updated.json'

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    print("ğŸ” æ£€æŸ¥ä¾èµ–...")

    deps = ['torch', 'transformers', 'sklearn', 'pandas', 'numpy', 'matplotlib', 'jieba', 'seaborn']

    missing = []
    for dep in deps:
        try:
            __import__(dep)
            print(f"  âœ… {dep}")
        except ImportError:
            print(f"  âŒ {dep} æœªå®‰è£…")
            missing.append(dep)

    if missing:
        print(f"\nâš ï¸  ç¼ºå°‘ä¾èµ–: {missing}")
        print("è¯·è¿è¡Œ: pip install " + " ".join(missing))
        return False

    return True

def run_lstm_training():
    """è¿è¡ŒLSTMæ¨¡å‹è®­ç»ƒ"""
    print("\nğŸš€ è¿è¡ŒLSTMæ¨¡å‹è®­ç»ƒ...")

    lstm_script = "models/lstm_model/train_lstm_global_vocab_visual_fixed.py"
    if os.path.exists(lstm_script):
        print(f"  è¿è¡Œå‘½ä»¤: python {lstm_script}")
        try:
            result = subprocess.run(["python", lstm_script], capture_output=True, text=True, cwd=".")
            if result.returncode == 0:
                print("  âœ… LSTMè®­ç»ƒæˆåŠŸå®Œæˆ")
                # æ˜¾ç¤ºæœ€åå‡ è¡Œè¾“å‡º
                lines = result.stdout.split('\n')[-10:]
                for line in lines:
                    if line.strip():
                        print(f"    {line}")
                return True
            else:
                print("  âŒ LSTMè®­ç»ƒå¤±è´¥")
                print(f"    é”™è¯¯: {result.stderr[-500:]}")
                return False
        except Exception as e:
            print(f"  âŒ LSTMè®­ç»ƒå¼‚å¸¸: {e}")
            return False
    else:
        print(f"  âŒ æ‰¾ä¸åˆ°LSTMè®­ç»ƒè„šæœ¬: {lstm_script}")
        return False

def run_model_comparison():
    """è¿è¡Œæ¨¡å‹å¯¹æ¯”åˆ†æ"""
    print("\nğŸ“Š è¿è¡Œæ¨¡å‹å¯¹æ¯”åˆ†æ...")

    comparison_script = "competition_report/updated_model_comparison.py"
    if os.path.exists(comparison_script):
        print(f"  è¿è¡Œå‘½ä»¤: python {comparison_script}")
        try:
            result = subprocess.run(["python", comparison_script], capture_output=True, text=True, cwd=".")
            if result.returncode == 0:
                print("  âœ… æ¨¡å‹å¯¹æ¯”åˆ†ææˆåŠŸå®Œæˆ")
                return True
            else:
                print("  âŒ æ¨¡å‹å¯¹æ¯”åˆ†æå¤±è´¥")
                print(f"    é”™è¯¯: {result.stderr[-500:]}")
                return False
        except Exception as e:
            print(f"  âŒ æ¨¡å‹å¯¹æ¯”åˆ†æå¼‚å¸¸: {e}")
            return False
    else:
        print(f"  âŒ æ‰¾ä¸åˆ°å¯¹æ¯”åˆ†æè„šæœ¬: {comparison_script}")
        return False

def main():
    print("="*70)
    print("æ™ºé“¾æ–°çºªæ¯”èµ› - äº¬ä¸œè¯„è®ºæƒ…æ„Ÿåˆ†æå®Œæ•´ç³»ç»Ÿï¼ˆä½¿ç”¨çœŸå®æ•°æ®ï¼‰")
    print("="*70)

    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        print("\nè¯·å…ˆå®‰è£…ç¼ºå¤±çš„ä¾èµ–")
        return

    # æ£€æŸ¥æ•°æ®
    print("\nğŸ“Š æ£€æŸ¥æ•°æ®...")
    data_files = ['data/train.csv', 'data/dev.csv']
    for file in data_files:
        if Path(file).exists():
            df = pd.read_csv(file)
            print(f"  âœ… {file}: {len(df):,} è¡Œ")
        else:
            print(f"  âŒ {file}: ä¸å­˜åœ¨")
            return

    # æ£€æŸ¥LSTMæ¨¡å‹æ•°æ®
    print("\nğŸ¤– æ£€æŸ¥LSTMæ¨¡å‹æ•°æ®...")
    lstm_data_files = [
        'models/lstm_model/lstm_training_log_fold_0.csv',
        'models/lstm_model/jd_lstm_fold_0_best_global.pt'
    ]
    lstm_data_exists = all(os.path.exists(f) for f in lstm_data_files)

    if lstm_data_exists:
        print("  âœ… å‘ç°å·²è®­ç»ƒçš„LSTMæ¨¡å‹æ•°æ®")
        use_existing = input("  æ˜¯å¦ä½¿ç”¨å·²æœ‰çš„LSTMæ•°æ®ï¼Ÿ(y/n): ").lower().strip()
        if use_existing == 'y':
            run_training = False
        else:
            run_training = True
    else:
        print("  âš ï¸ æœªå‘ç°LSTMæ¨¡å‹æ•°æ®ï¼Œéœ€è¦é‡æ–°è®­ç»ƒ")
        run_training = True

    # åˆ›å»ºé…ç½®æ–‡ä»¶
    print("\nâš™ï¸  åˆ›å»ºé…ç½®æ–‡ä»¶...")
    config_file = create_config()

    print("\nğŸš€ å¼€å§‹è¿è¡Œå®Œæ•´ç³»ç»Ÿ")
    print("-" * 70)

    # è¿è¡Œæ­¥éª¤
    steps = []

    if run_training:
        steps.append(("è®­ç»ƒLSTMæ¨¡å‹", "lstm_training"))
    else:
        print("â–¶ï¸  è·³è¿‡LSTMè®­ç»ƒï¼Œä½¿ç”¨å·²æœ‰æ•°æ®")

    steps.append(("ç”Ÿæˆæ¨¡å‹å¯¹æ¯”æŠ¥å‘Š", "model_comparison"))

    for step_name, step_type in steps:
        print(f"\nâ–¶ï¸  {step_name}...")

        if step_type == "lstm_training":
            success = run_lstm_training()
        elif step_type == "model_comparison":
            success = run_model_comparison()

        if success:
            print(f"  âœ… {step_name} æˆåŠŸ")
        else:
            print(f"  âŒ {step_name} å¤±è´¥")
            # ç»§ç»­ä¸‹ä¸€æ­¥

    print("\n" + "="*70)
    print("ğŸ‰ å®Œæ•´ç³»ç»Ÿè¿è¡Œå®Œæˆï¼")
    print("="*70)

    # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
    print("\nğŸ“ ç”Ÿæˆçš„ä¸»è¦æ–‡ä»¶:")
    output_files = [
        "models/lstm_model/lstm_training_log_fold_0.csv",
        "models/lstm_model/lstm_best_results_fold_0.csv",
        "models/lstm_model/jd_lstm_fold_0_best_global.pt",
        "models/lstm_model/visualizations/",
        "lstm_training_curves.png",
        "model_accuracy_comparison.png",
        "detailed_model_comparison.csv",
        "final_analysis_report.md"
    ]

    for file_path in output_files:
        if os.path.exists(file_path):
            if os.path.isdir(file_path):
                print(f"  âœ… {file_path} (ç›®å½•)")
            else:
                print(f"  âœ… {file_path}")
        else:
            print(f"  âš ï¸ {file_path} (æœªç”Ÿæˆ)")

    print("\nğŸ“„ æŠ¥å‘Šæ–‡ä»¶:")
    print("  - final_analysis_report.md (å®Œæ•´åˆ†ææŠ¥å‘Š)")
    print("  - detailed_model_comparison.csv (è¯¦ç»†å¯¹æ¯”æ•°æ®)")
    print("="*70)

if __name__ == "__main__":
    main()
