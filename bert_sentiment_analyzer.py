
"""
BERTé›†æˆæ¨¡å‹æƒ…æ„Ÿåˆ†æå™¨
æ”¯æŒç”¨æˆ·è¾“å…¥è¯„è®ºè¿›è¡Œæƒ…æ„Ÿåˆ†æé¢„æµ‹
"""

import os
import sys
import torch
import json
import numpy as np
import pandas as pd
from transformers import BertTokenizer, BertForSequenceClassification
import re
from datetime import datetime
import argparse

class BERTSentimentAnalyzer:
    """BERTé›†æˆæ¨¡å‹æƒ…æ„Ÿåˆ†æå™¨"""
    
    def __init__(self, ensemble_model_path='models/bert_model/bert_true_ensemble_model_cv.pt', 
                 device=None):
        """
        åˆå§‹åŒ–BERTæƒ…æ„Ÿåˆ†æå™¨
        
        Args:
            ensemble_model_path: é›†æˆæ¨¡å‹æ–‡ä»¶è·¯å¾„
            device: è®¡ç®—è®¾å¤‡ (é»˜è®¤è‡ªåŠ¨é€‰æ‹©)
        """
        self.ensemble_model_path = ensemble_model_path
        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.ensemble_data = None
        self.tokenizer = None
        self.models = []
        self.max_length = 128
        
        print(f"ğŸš€ åˆå§‹åŒ–BERTæƒ…æ„Ÿåˆ†æå™¨")
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ğŸ”„ åŠ è½½é›†æˆæ¨¡å‹: {ensemble_model_path}")
        
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½é›†æˆæ¨¡å‹"""
        try:
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.ensemble_model_path):
                raise FileNotFoundError(f"é›†æˆæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.ensemble_model_path}")
            
            # åŠ è½½é›†æˆæ¨¡å‹æ•°æ®
            print("ğŸ“Š åŠ è½½é›†æˆæ¨¡å‹æ•°æ®...")
            self.ensemble_data = torch.load(self.ensemble_model_path, 
                                          map_location='cpu', 
                                          weights_only=False)
            
            print(f"âœ… é›†æˆæ¨¡å‹ç‰ˆæœ¬: {self.ensemble_data.get('version', 'N/A')}")
            print(f"ğŸ“… åˆ›å»ºæ—¥æœŸ: {self.ensemble_data.get('created_date', 'N/A')}")
            
            # åŠ è½½tokenizer
            print("ğŸ”¤ åŠ è½½BERTåˆ†è¯å™¨...")
            tokenizer_info = self.ensemble_data.get('tokenizer_info', 'bert-base-chinese')
            self.tokenizer = BertTokenizer.from_pretrained(tokenizer_info)
            self.max_length = self.ensemble_data.get('max_len', 128)
            
            # é¢„åŠ è½½æ‰€æœ‰æ¨¡å‹
            print("ğŸ¤– é¢„åŠ è½½BERTæ¨¡å‹...")
            self.models = []
            
            model_configs = self.ensemble_data.get('model_configs', [])
            model_states = self.ensemble_data.get('models', [])
            
            for i, (state_dict, model_config) in enumerate(zip(model_states, model_configs)):
                try:
                    print(f"  åŠ è½½ç¬¬{i+1}ä¸ªæ¨¡å‹...")
                    model = BertForSequenceClassification.from_pretrained(
                        model_config.get('model_path', 'bert-base-chinese'),
                        num_labels=model_config.get('num_labels', 2)
                    )
                    model.load_state_dict(state_dict)
                    model.to(self.device)
                    model.eval()
                    self.models.append(model)
                except Exception as e:
                    print(f"  âŒ ç¬¬{i+1}ä¸ªæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                    continue
            
            if not self.models:
                raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ¨¡å‹")
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.models)} ä¸ªBERTæ¨¡å‹")
            
            # æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½
            performance = self.ensemble_data.get('performance', {})
            if performance:
                print(f"\nğŸ“ˆ æ¨¡å‹æ€§èƒ½:")
                print(f"  å•æ¨¡å‹å‡†ç¡®ç‡: {performance.get('single_model_acc', 0):.4f}")
                print(f"  é›†æˆè½¯æŠ•ç¥¨å‡†ç¡®ç‡: {performance.get('ensemble_soft_acc', 0):.4f}")
                print(f"  é›†æˆç¡¬æŠ•ç¥¨å‡†ç¡®ç‡: {performance.get('ensemble_hard_acc', 0):.4f}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _clean_text(self, text):
        """æ¸…ç†æ–‡æœ¬"""
        if not text or pd.isna(text):
            return ""
        
        text = str(text).strip()
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œ
        text = re.sub(r'\s+', ' ', text)
        # ç§»é™¤HTMLæ ‡ç­¾
        text = re.sub(r'<[^>]+>', '', text)
        # ç§»é™¤URL
        text = re.sub(r'http\S+|www\S+|https\S+', '', text)
        # ç§»é™¤é‚®ç®±
        text = re.sub(r'\S+@\S+', '', text)
        
        return text.strip()
    
    def _encode_text(self, text):
        """ç¼–ç æ–‡æœ¬"""
        encoding = self.tokenizer.encode_plus(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].to(self.device),
            'attention_mask': encoding['attention_mask'].to(self.device)
        }
    
    def predict_single(self, text, method='soft_voting'):
        """
        é¢„æµ‹å•ä¸ªæ–‡æœ¬çš„æƒ…æ„Ÿ
        
        Args:
            text: å¾…åˆ†æçš„æ–‡æœ¬
            method: é›†æˆæ–¹æ³• ('soft_voting' æˆ– 'hard_voting')
            
        Returns:
            dict: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        if not text or not text.strip():
            return {
                'text': text,
                'sentiment': 'æ— æ³•åˆ†æ',
                'confidence': 0.0,
                'prediction': -1,
                'probabilities': [0.5, 0.5],
                'method': method,
                'error': 'è¾“å…¥æ–‡æœ¬ä¸ºç©º'
            }
        
        # æ¸…ç†æ–‡æœ¬
        clean_text = self._clean_text(text)
        
        if not clean_text:
            return {
                'text': text,
                'sentiment': 'æ— æ³•åˆ†æ',
                'confidence': 0.0,
                'prediction': -1,
                'probabilities': [0.5, 0.5],
                'method': method,
                'error': 'æ–‡æœ¬æ¸…ç†åä¸ºç©º'
            }
        
        # ç¼–ç æ–‡æœ¬
        inputs = self._encode_text(clean_text)
        
        try:
            with torch.no_grad():
                if method == 'soft_voting':
                    return self._soft_voting_predict(inputs, clean_text)
                elif method == 'hard_voting':
                    return self._hard_voting_predict(inputs, clean_text)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„é›†æˆæ–¹æ³•: {method}")
                    
        except Exception as e:
            return {
                'text': text,
                'sentiment': 'é¢„æµ‹å¤±è´¥',
                'confidence': 0.0,
                'prediction': -1,
                'probabilities': [0.5, 0.5],
                'method': method,
                'error': str(e)
            }
    
    def _soft_voting_predict(self, inputs, original_text):
        """è½¯æŠ•ç¥¨é¢„æµ‹"""
        all_probs = []
        
        for model in self.models:
            outputs = model(**inputs)
            probs = torch.softmax(outputs.logits, dim=1)
            all_probs.append(probs)
        
        # å¹³å‡æ¦‚ç‡
        avg_probs = torch.mean(torch.stack(all_probs), dim=0)
        prediction = torch.argmax(avg_probs, dim=1).item()
        confidence = torch.max(avg_probs).item()
        
        sentiment = "æ­£é¢" if prediction == 1 else "è´Ÿé¢"
        probs_list = avg_probs.cpu().numpy().tolist()[0]
        
        return {
            'text': original_text,
            'sentiment': sentiment,
            'confidence': confidence,
            'prediction': prediction,
            'probabilities': probs_list,
            'method': 'soft_voting',
            'negative_prob': probs_list[0],
            'positive_prob': probs_list[1]
        }
    
    def _hard_voting_predict(self, inputs, original_text):
        """ç¡¬æŠ•ç¥¨é¢„æµ‹"""
        all_predictions = []
        
        for model in self.models:
            outputs = model(**inputs)
            prediction = torch.argmax(outputs.logits, dim=1).item()
            all_predictions.append(prediction)
        
        # å¤šæ•°ç¥¨å†³ç­–
        vote_0 = all_predictions.count(0)
        vote_1 = all_predictions.count(1)
        
        if vote_0 > vote_1:
            final_prediction = 0
            confidence = vote_0 / len(all_predictions)
        else:
            final_prediction = 1
            confidence = vote_1 / len(all_predictions)
        
        sentiment = "æ­£é¢" if final_prediction == 1 else "è´Ÿé¢"
        
        return {
            'text': original_text,
            'sentiment': sentiment,
            'confidence': confidence,
            'prediction': final_prediction,
            'probabilities': [vote_0/len(all_predictions), vote_1/len(all_predictions)],
            'method': 'hard_voting',
            'votes': {'negative': vote_0, 'positive': vote_1}
        }
    
    def predict_batch(self, texts, method='soft_voting', show_progress=True):
        """æ‰¹é‡é¢„æµ‹"""
        results = []
        
        print(f"ğŸ”„ å¼€å§‹æ‰¹é‡é¢„æµ‹ ({len(texts)} ä¸ªæ–‡æœ¬)")
        
        for i, text in enumerate(texts):
            if show_progress and i % 10 == 0:
                print(f"  å¤„ç†è¿›åº¦: {i+1}/{len(texts)}")
            
            result = self.predict_single(text, method)
            results.append(result)
        
        print(f"âœ… æ‰¹é‡é¢„æµ‹å®Œæˆ")
        return results
    
    def analyze_sentiment(self, text, method='soft_voting'):
        """åˆ†ææ–‡æœ¬æƒ…æ„Ÿï¼ˆç»Ÿä¸€æ¥å£ï¼‰"""
        return self.predict_single(text, method)

def print_result(result):
    """æ‰“å°é¢„æµ‹ç»“æœ"""
    if 'error' in result:
        print(f"âŒ é”™è¯¯: {result['error']}")
        return
    
    sentiment = result['sentiment']
    confidence = result['confidence']
    method = result['method']
    
    # æ ¹æ®ç½®ä¿¡åº¦è®¾ç½®è¡¨æƒ…ç¬¦å·
    if confidence >= 0.9:
        emoji = "ğŸŸ¢"
    elif confidence >= 0.7:
        emoji = "ğŸŸ¡"
    else:
        emoji = "ğŸ”´"
    
    print(f"\n{emoji} æƒ…æ„Ÿåˆ†æç»“æœ:")
    print(f"ğŸ“ æ–‡æœ¬: {result['text']}")
    print(f"ğŸ˜Š æƒ…æ„Ÿ: {sentiment}")
    print(f"ğŸ¯ ç½®ä¿¡åº¦: {confidence:.1%}")
    print(f"âš™ï¸ æ–¹æ³•: {method}")
    
    # æ˜¾ç¤ºæ¦‚ç‡åˆ†å¸ƒ
    if 'negative_prob' in result:
        print(f"ğŸ“Š æ¦‚ç‡åˆ†å¸ƒ:")
        print(f"   è´Ÿé¢: {result['negative_prob']:.1%}")
        print(f"   æ­£é¢: {result['positive_prob']:.1%}")
    elif 'votes' in result:
        print(f"ğŸ—³ï¸ æŠ•ç¥¨ç»“æœ:")
        print(f"   è´Ÿé¢ç¥¨æ•°: {result['votes']['negative']}")
        print(f"   æ­£é¢ç¥¨æ•°: {result['votes']['positive']}")

def interactive_mode(analyzer):
    """äº¤äº’æ¨¡å¼"""
    print("\n" + "="*60)
    print("ğŸ¤– BERTæƒ…æ„Ÿåˆ†æå™¨ - è¯„è®ºæƒ…æ„Ÿè¯„ä»·ç³»ç»Ÿ")
    print("="*60)
    print("âœ… ç³»ç»Ÿå·²å°±ç»ªï¼è¯·è¾“å…¥æ‚¨çš„è¯„è®ºï¼Œæˆ‘ä»¬å°†ä¸ºæ‚¨åˆ†ææƒ…æ„Ÿå€¾å‘")
    print("ğŸ“ è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ© | è¾“å…¥ 'quit' é€€å‡º")
    print("ğŸ¯ å½“å‰ä½¿ç”¨è½¯æŠ•ç¥¨æ¨¡å¼ï¼ˆæ¨èï¼‰")
    print("="*60)
    
    method = 'soft_voting'
    
    while True:
        try:
            user_input = input(f"\nğŸ¯ [{method}] è¯·è¾“å…¥è¯„è®º: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨BERTæƒ…æ„Ÿåˆ†æå™¨ï¼")
                break
            
            elif user_input.lower() == 'help':
                print("\nğŸ“š å¸®åŠ©ä¿¡æ¯:")
                print("  - è¾“å…¥è¯„è®ºæ–‡æœ¬è¿›è¡Œåˆ†æ")
                print("  - è¾“å…¥ 'mode' åˆ‡æ¢é›†æˆæ–¹æ³•")
                print("  - è¾“å…¥ 'quit' é€€å‡ºç¨‹åº")
                print("\nğŸ” é›†æˆæ–¹æ³•è¯´æ˜:")
                print("  - soft_voting: è½¯æŠ•ç¥¨ï¼ˆæ¨èï¼‰ï¼Œç»¼åˆæ¦‚ç‡ï¼Œç²¾åº¦æ›´é«˜")
                print("  - hard_voting: ç¡¬æŠ•ç¥¨ï¼Œå¤šæ•°å†³ç­–ï¼Œç¨³å®šå¯é ")
                continue
            
            elif user_input.lower() == 'mode':
                if method == 'soft_voting':
                    method = 'hard_voting'
                    print("ğŸ”„ å·²åˆ‡æ¢åˆ°ç¡¬æŠ•ç¥¨æ¨¡å¼")
                else:
                    method = 'soft_voting'
                    print("ğŸ”„ å·²åˆ‡æ¢åˆ°è½¯æŠ•ç¥¨æ¨¡å¼")
                continue
            
            elif not user_input:
                print("è¾“å…¥æœ‰æ•ˆçš„æ–‡æœ¬å†…å®¹")
                continue
            
            # è¿›è¡Œæƒ…æ„Ÿåˆ†æ
            result = analyzer.analyze_sentiment(user_input, method)
            print_result(result)
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
            break
        except Exception as e:
            print(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

def demo_mode(analyzer):
    """æ¼”ç¤ºæ¨¡å¼"""
    print("\n" + "="*60)
    print("ğŸ­ BERTæƒ…æ„Ÿåˆ†æå™¨ - æ¼”ç¤ºæ¨¡å¼")
    print("="*60)
    
    # ç¤ºä¾‹è¯„è®º
    demo_texts = [
        "è¿™ä¸ªå•†å“è´¨é‡çœŸçš„å¾ˆå¥½ï¼Œéå¸¸æ»¡æ„ï¼",
        "ç‰©æµå¤ªæ…¢äº†ï¼Œç­‰äº†æ•´æ•´ä¸€ä¸ªæ˜ŸæœŸ",
        "æ€§ä»·æ¯”å¾ˆé«˜ï¼Œæ¨èè´­ä¹°",
        "åŒ…è£…ç ´æŸï¼Œå•†å“æœ‰ç‘•ç–µ",
        "æœåŠ¡æ€åº¦å·®ï¼Œå®¢æœä¸ä¸“ä¸š",
        "ä»·æ ¼å®æƒ ï¼Œè´¨é‡ä¹Ÿä¸é”™",
        "äº§å“è®¾è®¡å¾ˆæ£’ï¼ŒåŠŸèƒ½å¼ºå¤§",
        "ä½¿ç”¨ä½“éªŒä¸€èˆ¬ï¼Œæ²¡æœ‰æƒ³è±¡ä¸­å¥½"
    ]
    
    print("ğŸ“‹ ç¤ºä¾‹è¯„è®ºæƒ…æ„Ÿåˆ†æ:")
    
    for i, text in enumerate(demo_texts, 1):
        print(f"\n{i}. æ–‡æœ¬: {text}")
        result = analyzer.analyze_sentiment(text, 'soft_voting')
        print_result(result)

def batch_mode(analyzer, file_path, output_path=None):
    """æ‰¹é‡å¤„ç†æ¨¡å¼"""
    try:
        print(f"\n" + "="*60)
        print(f"ğŸ“ æ‰¹é‡å¤„ç†æ¨¡å¼")
        print("="*60)
        
        # è¯»å–æ–‡ä»¶
        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path)
            if 'text' in df.columns:
                texts = df['text'].tolist()
            elif 'sentence' in df.columns:
                texts = df['sentence'].tolist()
            else:
                raise ValueError("CSVæ–‡ä»¶éœ€è¦åŒ…å«'text'æˆ–'sentence'åˆ—")
        elif file_path.endswith('.txt'):
            with open(file_path, 'r', encoding='utf-8') as f:
                texts = [line.strip() for line in f if line.strip()]
        else:
            raise ValueError("æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .csv, .txt")
        
        print(f"ğŸ“– è¯»å–åˆ° {len(texts)} æ¡æ–‡æœ¬")
        
        # æ‰¹é‡é¢„æµ‹
        results = analyzer.predict_batch(texts, 'soft_voting')
        
        # ä¿å­˜ç»“æœ
        if output_path:
            if output_path.endswith('.csv'):
                result_df = pd.DataFrame(results)
                result_df.to_csv(output_path, index=False, encoding='utf-8')
            elif output_path.endswith('.json'):
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
            else:
                raise ValueError("è¾“å‡ºæ–‡ä»¶æ ¼å¼æ”¯æŒ: .csv, .json")
            
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        # ç»Ÿè®¡ç»“æœ
        sentiments = [r['sentiment'] for r in results if 'sentiment' in r]
        positive_count = sentiments.count('æ­£é¢')
        negative_count = sentiments.count('è´Ÿé¢')
        
        print(f"\nğŸ“Š æ‰¹é‡åˆ†æç»Ÿè®¡:")
        print(f"  æ€»æ•°: {len(sentiments)}")
        print(f"  æ­£é¢: {positive_count} ({positive_count/len(sentiments)*100:.1f}%)")
        print(f"  è´Ÿé¢: {negative_count} ({negative_count/len(sentiments)*100:.1f}%)")
        
        return results
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
        return []

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='BERTé›†æˆæ¨¡å‹æƒ…æ„Ÿåˆ†æå™¨')
    parser.add_argument('--model', type=str, 
                       default='models/bert_model/bert_true_ensemble_model_cv.pt',
                       help='é›†æˆæ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--mode', type=str, choices=['interactive', 'demo', 'batch'],
                       default='interactive', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--file', type=str, help='æ‰¹é‡å¤„ç†æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, help='æ‰¹é‡å¤„ç†è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--device', type=str, help='è®¡ç®—è®¾å¤‡')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–åˆ†æå™¨
        analyzer = BERTSentimentAnalyzer(args.model, args.device)
        
        # æ ¹æ®æ¨¡å¼è¿è¡Œ
        if args.mode == 'interactive':
            interactive_mode(analyzer)
        elif args.mode == 'demo':
            demo_mode(analyzer)
        elif args.mode == 'batch':
            if not args.file:
                print("âŒ æ‰¹é‡æ¨¡å¼éœ€è¦æŒ‡å®šæ–‡ä»¶è·¯å¾„ (--file)")
                return
            batch_mode(analyzer, args.file, args.output)
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å¼: {args.mode}")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œï¼Œé»˜è®¤ä¸ºäº¤äº’æ¨¡å¼
    if len(sys.argv) == 1:
        try:
            analyzer = BERTSentimentAnalyzer()
            interactive_mode(analyzer)
        except Exception as e:
            print(f"âŒ ç¨‹åºè¿è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    else:
        main()
