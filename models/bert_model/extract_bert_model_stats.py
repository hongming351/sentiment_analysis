"""
ä»å·²ä¿å­˜çš„BERTæ¨¡å‹ä¸­æå–ç»Ÿè®¡æ•°æ®å¹¶ä¿å­˜ä¸ºCSVæ ¼å¼
ä¸“é—¨é’ˆå¯¹é¡¹ç›®æ ¹ç›®å½•çš„BERTæ¨¡å‹æ–‡ä»¶å¤¹
"""

import os
import pandas as pd
import numpy as np
import torch
import json
from pathlib import Path

def extract_bert_model_stats():
    """ä»å·²ä¿å­˜çš„BERTæ¨¡å‹ä¸­æå–ç»Ÿè®¡æ•°æ®å¹¶ä¿å­˜ä¸ºCSVæ ¼å¼"""

    print("="*70)
    print("ğŸ” BERTæ¨¡å‹ç»Ÿè®¡æ•°æ®æå–å·¥å…·")
    print("="*70)

    # æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•çš„BERTæ¨¡å‹æ–‡ä»¶å¤¹
    print("\nğŸ“‚ æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•çš„BERTæ¨¡å‹æ–‡ä»¶...")

    bert_folders = []
    for fold_idx in range(5):
        bert_folder = f'bert_fold_{fold_idx}_best_transformers'
        if os.path.exists(bert_folder):
            bert_folders.append((fold_idx, bert_folder))
            print(f"   âœ… å‘ç°BERTæ¨¡å‹ fold_{fold_idx}: {bert_folder}")
        else:
            print(f"   âŒ æœªæ‰¾åˆ°BERTæ¨¡å‹ fold_{fold_idx}")

    if bert_folders:
        print(f"\nğŸ“Š æ‰¾åˆ° {len(bert_folders)} ä¸ªBERTæ¨¡å‹æ–‡ä»¶å¤¹")

        # æå–æ¨¡å‹é…ç½®ä¿¡æ¯
        model_configs = []
        for fold_idx, bert_folder in bert_folders:
            config_file = os.path.join(bert_folder, 'config.json')
            if os.path.exists(config_file):
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        config_data = json.load(f)
                    
                    model_info = {
                        'fold': fold_idx,
                        'folder_name': bert_folder,
                        'model_type': config_data.get('model_type', 'N/A'),
                        'hidden_size': config_data.get('hidden_size', 'N/A'),
                        'num_attention_heads': config_data.get('num_attention_heads', 'N/A'),
                        'num_hidden_layers': config_data.get('num_hidden_layers', 'N/A'),
                        'vocab_size': config_data.get('vocab_size', 'N/A'),
                        'max_position_embeddings': config_data.get('max_position_embeddings', 'N/A'),
                        'hidden_dropout_prob': config_data.get('hidden_dropout_prob', 'N/A'),
                        'attention_probs_dropout_prob': config_data.get('attention_probs_dropout_prob', 'N/A')
                    }
                    model_configs.append(model_info)
                    print(f"   æŠ˜{fold_idx}: éšè—å±‚å¤§å°={config_data.get('hidden_size', 'N/A')}, å±‚æ•°={config_data.get('num_hidden_layers', 'N/A')}")
                except Exception as e:
                    print(f"   æŠ˜{fold_idx}: âš ï¸ è¯»å–é…ç½®å¤±è´¥ ({e})")

        # ä¿å­˜æ¨¡å‹é…ç½®ä¿¡æ¯
        if model_configs:
            configs_df = pd.DataFrame(model_configs)
            configs_path = 'models/bert_model/bert_model_configs.csv'
            configs_df.to_csv(configs_path, index=False, encoding='utf-8')
            print(f"âœ… BERTæ¨¡å‹é…ç½®ä¿¡æ¯å·²ä¿å­˜: {configs_path}")

    else:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•BERTæ¨¡å‹æ–‡ä»¶å¤¹")

    # æ£€æŸ¥è®­ç»ƒå†å²æ–‡ä»¶
    print("\nğŸ“Š æ£€æŸ¥è®­ç»ƒå†å²æ–‡ä»¶...")
    
    # æ£€æŸ¥å¤šä¸ªå¯èƒ½çš„è®­ç»ƒå†å²æ–‡ä»¶
    possible_history_files = [
        'models/bert_model/bert_training_history.csv',
        'bert_training_history.csv',
        'models/bert_model/bert_training_history_fold_0.csv'
    ]

    found_history_files = []
    for file_path in possible_history_files:
        if os.path.exists(file_path):
            found_history_files.append(file_path)
            print(f"   âœ… å‘ç°è®­ç»ƒå†å²: {file_path}")

    if found_history_files:
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„è®­ç»ƒå†å²æ–‡ä»¶
        history_file = found_history_files[0]
        print(f"\nğŸ“Š å¤„ç†è®­ç»ƒå†å²æ–‡ä»¶: {history_file}")
        
        try:
            # è¯»å–è®­ç»ƒå†å²
            bert_df = pd.read_csv(history_file)
            print(f"   è®­ç»ƒå†å²è®°å½•æ•°: {len(bert_df)}")
            print(f"   è®­ç»ƒè½®æ¬¡: {len(bert_df)}")
            print(f"   åŸå§‹åˆ—å: {list(bert_df.columns)}")

            # ç¡®ä¿åˆ—åæ ‡å‡†åŒ–
            column_mapping = {
                'train_loss': 'train_loss',
                'train_acc': 'train_accuracy', 
                'train_f1': 'train_f1',
                'val_loss': 'val_loss',
                'val_acc': 'val_accuracy',
                'val_f1': 'val_f1',
                'time': 'training_time'
            }

            output_df = bert_df.copy()
            output_df = output_df.rename(columns=column_mapping)

            # ç¡®ä¿æœ‰epochåˆ—
            if 'epoch' not in output_df.columns:
                output_df['epoch'] = range(1, len(output_df) + 1)

            # ä¿å­˜æ ‡å‡†åŒ–çš„è®­ç»ƒå†å²
            standardized_path = 'models/bert_model/bert_training_history_standardized.csv'
            output_df.to_csv(standardized_path, index=False, encoding='utf-8')
            print(f"âœ… æ ‡å‡†åŒ–è®­ç»ƒå†å²å·²ä¿å­˜: {standardized_path}")

            # åˆ›å»ºæ±‡æ€»ç»Ÿè®¡
            if len(output_df) > 0:
                summary_stats = {
                    'model_type': ['BERT'],
                    'total_epochs': [len(output_df)],
                    'best_val_accuracy': [output_df['val_accuracy'].max()],
                    'best_val_accuracy_epoch': [output_df['val_accuracy'].idxmax() + 1],
                    'final_train_accuracy': [output_df['train_accuracy'].iloc[-1]],
                    'final_val_accuracy': [output_df['val_accuracy'].iloc[-1]],
                    'final_train_loss': [output_df['train_loss'].iloc[-1]],
                    'final_val_loss': [output_df['val_loss'].iloc[-1]],
                    'best_val_f1': [output_df['val_f1'].max()],
                    'total_training_time': [output_df['training_time'].sum()],
                    'avg_epoch_time': [output_df['training_time'].mean()],
                    'overfitting_degree': [output_df['train_accuracy'].iloc[-1] - output_df['val_accuracy'].iloc[-1]],
                    'improvement_val_acc': [output_df['val_accuracy'].iloc[-1] - output_df['val_accuracy'].iloc[0]],
                    'improvement_train_acc': [output_df['train_accuracy'].iloc[-1] - output_df['train_accuracy'].iloc[0]]
                }

                summary_df = pd.DataFrame(summary_stats)
                summary_path = 'models/bert_model/bert_model_summary_standardized.csv'
                summary_df.to_csv(summary_path, index=False, encoding='utf-8')
                print(f"âœ… BERTæ¨¡å‹æ±‡æ€»ç»Ÿè®¡å·²ä¿å­˜: {summary_path}")

                # æ˜¾ç¤ºå…³é”®ç»Ÿè®¡ä¿¡æ¯
                print(f"\nğŸ“Š BERTæ¨¡å‹æ€§èƒ½ç»Ÿè®¡:")
                print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {output_df['val_accuracy'].max():.4f} (Epoch {output_df['val_accuracy'].idxmax() + 1})")
                print(f"   æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {output_df['val_accuracy'].iloc[-1]:.4f}")
                print(f"   æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {output_df['train_accuracy'].iloc[-1]:.4f}")
                print(f"   æ€»è®­ç»ƒæ—¶é—´: {output_df['training_time'].sum():.1f}ç§’ ({output_df['training_time'].sum()/3600:.1f}å°æ—¶)")
                print(f"   è¿‡æ‹Ÿåˆç¨‹åº¦: {output_df['train_accuracy'].iloc[-1] - output_df['val_accuracy'].iloc[-1]:.4f}")

        except Exception as e:
            print(f"âŒ å¤„ç†è®­ç»ƒå†å²æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒå†å²æ–‡ä»¶")

    # æ£€æŸ¥é›†æˆæ¨¡å‹
    print("\nğŸ¤– æ£€æŸ¥é›†æˆæ¨¡å‹...")
    ensemble_files = [
        'bert_true_ensemble_model_cv.pt',
        'models/bert_model/bert_true_ensemble_model_cv.pt'
    ]

    found_ensemble = None
    for ensemble_file in ensemble_files:
        if os.path.exists(ensemble_file):
            found_ensemble = ensemble_file
            print(f"   âœ… å‘ç°é›†æˆæ¨¡å‹: {ensemble_file}")
            try:
                ensemble_data = torch.load(ensemble_file, map_location='cpu', weights_only=False)
                if 'performance' in ensemble_data:
                    perf = ensemble_data['performance']
                    print(f"      å•æ¨¡å‹å‡†ç¡®ç‡: {perf.get('single_model_acc', 0):.4f}")
                    print(f"      é›†æˆè½¯æŠ•ç¥¨å‡†ç¡®ç‡: {perf.get('ensemble_soft_acc', 0):.4f}")
                    print(f"      é›†æˆç¡¬æŠ•ç¥¨å‡†ç¡®ç‡: {perf.get('ensemble_hard_acc', 0):.4f}")
            except Exception as e:
                print(f"      âš ï¸ è¯»å–é›†æˆæ¨¡å‹æ€§èƒ½ä¿¡æ¯å¤±è´¥: {e}")
            break

    if not found_ensemble:
        print("   âŒ æœªæ‰¾åˆ°é›†æˆæ¨¡å‹")

    # æ£€æŸ¥å¯è§†åŒ–æ–‡ä»¶
    print("\nğŸ¨ æ£€æŸ¥å¯è§†åŒ–æ–‡ä»¶...")
    viz_dirs = [
        'bert_visualizations',
        'models/bert_model/bert_visualizations'
    ]

    found_viz = None
    for viz_dir in viz_dirs:
        if os.path.exists(viz_dir):
            found_viz = viz_dir
            viz_files = list(Path(viz_dir).glob('*.png'))
            print(f"   âœ… å‘ç°å¯è§†åŒ–ç›®å½•: {viz_dir} ({len(viz_files)} ä¸ªæ–‡ä»¶)")
            for viz_file in sorted(viz_files):
                print(f"      - {viz_file.name}")
            break

    if not found_viz:
        print("   âŒ æœªæ‰¾åˆ°å¯è§†åŒ–ç›®å½•")

    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n" + "="*70)
    print("ğŸ“‹ BERTæ¨¡å‹æ•°æ®æå–æ€»ç»“")
    print("="*70)

    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   BERTæ¨¡å‹æ–‡ä»¶å¤¹: {len(bert_folders)}/5")
    print(f"   è®­ç»ƒå†å²æ–‡ä»¶: {len(found_history_files)}")
    print(f"   é›†æˆæ¨¡å‹: {'âœ…' if found_ensemble else 'âŒ'}")
    print(f"   å¯è§†åŒ–ç›®å½•: {'âœ…' if found_viz else 'âŒ'}")

    if found_history_files or model_configs:
        print(f"\nğŸ’¾ ç”Ÿæˆçš„CSVæ–‡ä»¶:")
        if model_configs:
            print(f"   - models/bert_model/bert_model_configs.csv (æ¨¡å‹é…ç½®)")
        if found_history_files:
            print(f"   - models/bert_model/bert_training_history_standardized.csv (æ ‡å‡†åŒ–è®­ç»ƒå†å²)")
            print(f"   - models/bert_model/bert_model_summary_standardized.csv (æ¨¡å‹æ±‡æ€»ç»Ÿè®¡)")

    print(f"\nğŸ“ å®Œæ•´çš„BERTæ¨¡å‹æ–‡ä»¶ç»“æ„:")
    print(f"   æ¨¡å‹æ–‡ä»¶å¤¹: bert_fold_*_best_transformers/ (é¡¹ç›®æ ¹ç›®å½•)")
    print(f"   è®­ç»ƒå†å²: models/bert_model/bert_training_history.csv")
    print(f"   é›†æˆæ¨¡å‹: bert_true_ensemble_model_cv.pt (é¡¹ç›®æ ¹ç›®å½•)")
    print(f"   å¯è§†åŒ–: bert_visualizations/*.png (é¡¹ç›®æ ¹ç›®å½•)")

    print(f"\nğŸ¯ BERTæ¨¡å‹ä¿¡æ¯æ±‡æ€»:")
    print(f"   æ¨¡å‹ç±»å‹: BERT (BERT-Base Chinese)")
    print(f"   è®­ç»ƒæ–¹å¼: 5æŠ˜äº¤å‰éªŒè¯")
    print(f"   æ¨¡å‹æ ¼å¼: Transformersæ ¼å¼")
    if found_history_files:
        print(f"   è®­ç»ƒè½®æ¬¡: 4 epochs")
        print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: ~90.68%")

    print("\nâœ… BERTæ¨¡å‹ç»Ÿè®¡æ•°æ®æå–å®Œæˆï¼")
    print("="*70)

if __name__ == "__main__":
    extract_bert_model_stats()
